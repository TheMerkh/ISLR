{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06ed3f7",
   "metadata": {},
   "source": [
    "Q: Using the Boston data set, fit classification models in order to predict whether a given suburb has a crime rate above or below the median. Explore logistic regression, LDA, and KNN models using various subsets of the predictors. Describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e7fbc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0       0  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1       0   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2       0   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3       0   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4       0   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "..    ...   ...    ...   ...    ...    ...   ...     ...  ...  ...      ...   \n",
       "501     0   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273     21.0   \n",
       "502     0   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273     21.0   \n",
       "503     0   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273     21.0   \n",
       "504     0   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273     21.0   \n",
       "505     0   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273     21.0   \n",
       "\n",
       "      black  lstat  medv  \n",
       "0    396.90   4.98  24.0  \n",
       "1    396.90   9.14  21.6  \n",
       "2    392.83   4.03  34.7  \n",
       "3    394.63   2.94  33.4  \n",
       "4    396.90   5.33  36.2  \n",
       "..      ...    ...   ...  \n",
       "501  391.99   9.67  22.4  \n",
       "502  396.90   9.08  20.6  \n",
       "503  396.90   5.64  23.9  \n",
       "504  393.45   6.48  22.0  \n",
       "505  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Boston.csv\")\n",
    "\n",
    "df[\"crim\"] = pd.factorize(df[\"crim\"] > df[\"crim\"].median())[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a7aabc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8414666666666666\n"
     ]
    }
   ],
   "source": [
    "#Logistical Regresion\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "\n",
    "X = df.drop(columns=['crim'])\n",
    "y = df['crim']\n",
    "\n",
    "logreg_model = LogisticRegression(fit_intercept=True, max_iter=4000)\n",
    "\n",
    "scores = []\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    score = logreg_model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "\n",
    "print(mean_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e2f6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8477960784313727\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=2)\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "scores = []\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    lda_model.fit(X_train, y_train)\n",
    "    score = lda_model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "\n",
    "print(mean_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66f51335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7337144053676491\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=4)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 21, 2)}\n",
    "\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=cv)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8b19b",
   "metadata": {},
   "source": [
    "#A: The best model is the LDA, although with a very tight margin with the logistic regression, in turn the worst is the KNN, very probably due to its simplicity, this could possibly improve if we filtered from the best predictor to the worst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
